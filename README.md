My Local RAG Chatbot Project

Project Description

I built an awesome local Retrieval Augmented Generation (RAG) chatbot using Python, Olama, Langchain, Streamlit, and Chroma DB! This project came from my realization that standalone large language models (LLMs) have limitsâ€”they can give wrong or unsourced answers since their training data isnâ€™t fully controllable. My RAG chatbot fixes that by delivering accurate, sourced responses, and Iâ€™m excited to share how it works!

The star of this project is the "Agentic RAG" approach, which I found to be a huge step up from basic "naive RAG." Naive RAG struggles with follow-up questions because the database doesnâ€™t track the conversation, but my Agentic RAG uses an agent to rewrite queries based on chat history. This keeps everything contextual and the answers spot-on, even as the convo flows!

Hereâ€™s how I set it up: I used Olama to run LLMs locally, picking a chat model (like a tool-calling Llama 3.2) and an embedding model based on my hardware. Embeddings were a big "aha" for meâ€”these multi-dimensional numbers capture text meaning, letting my chatbot find semantically similar content instead of just keywords.

My data pipeline is robust and covers everything:





Data Scraping: I used Bright Data to scrape Wikipedia based on topics I set in a keywords.txt file (like "Python" or "Langchain"), controlling depth with options like pages=1 for direct articles or more.



Text Chunking: Long articles get split into smaller, 1000-character chunks for easier retrieval.



Embedding Generation: Each chunk turns into a numerical embedding.



Data Ingestion: Chunks and embeddings go into Chroma DB, my local vector store.

I cloned a GitHub repo with three key scripts:





one_scraping_wikipedia.py: Starts the Wikipedia scrape with Bright Data, saving a snapshot.txt to track progress.



two_chunking_embedding_ingestion.py: Fetches scraped data, chunks it, creates embeddings, and loads them into Chroma DB.



three_chatbot.py: Launches a Streamlit interface, tying the LLM, retrieval from Chroma DB, and agentic logic for accurate, sourced replies.

To get it running, I set up a virtual environment, installed dependencies from requirements.txt, and tweaked an .env file with my models and Bright Data API key. I love how I can swap in other LLM providers like OpenAI or Anthropic just by updating the .env!

The result? My chatbot gives precise, sourced answers, way better than a plain LLM. Iâ€™m thrilled with this local, controllable AIâ€”itâ€™s perfect for reliable, custom projects!

Highlights





ğŸ¤– Agentic RAG Rocks: My Agentic RAG beats naive RAG by keeping convo context and rewriting queries for great follow-ups.



ğŸ’» Local LLMs with Olama: I run models locally with Olama, choosing chat and embedding models to fit my setup.



ğŸ“Š Full Data Pipeline: Scraping Wikipedia, chunking text, making embeddings, and storing in Chroma DBâ€”my pipelineâ€™s solid!



ğŸ§  Embeddings Power: I learned embeddings use multi-dimensional numbers for meaning, enabling smart searches.



ğŸ› ï¸ Easy Setup: Cloned the repo, set up a virtual env, installed dependencies, and configured the .env file.



ğŸŒ Custom Topics: I edit keywords.txt to pick topics like Python, tailoring my chatbot without code changes.



âœ… Sourced Answers: My demo shows accurate replies with sources, fixing LLM flaws.

Key Takeaways





ğŸ§  Better Chats with Agentic RAG: I see why naive RAG strugglesâ€”Agentic RAG uses chat history for relevant, flowing responses.



ğŸ”’ Local Power: Running LLMs locally with Olama gives me privacy, no API costs, and full controlâ€”great for sensitive use!



ğŸ—ï¸ Strong Pipeline: My scraping-to-ingestion pipeline, with Bright Data and chunking, makes this scalable and reliable.



ğŸ¯ Embeddings Are Key: Multi-dimensional embeddings let my database match meaning, not just wordsâ€”super cool!



âš™ï¸ Flexible Design: I can tweak models or topics via .env and keywords.txt for easy customization.



ğŸš€ Streamlit Speed: Streamlit made my UI quick and simple, letting me focus on the RAG logic.



âœ… Fixing LLMs: My RAG system beats LLM issues like wrong facts, giving reliable, sourced answers for real use.
